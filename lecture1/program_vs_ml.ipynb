{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7c9dd1",
   "metadata": {},
   "source": [
    "# Regular Programming vs Machine Learning\n",
    "\n",
    "In regular programming we process inputs and transform them to obtain outputs. For example, if I want to convert Celsius degrees to Fahrenheit degrees, I can implement the formula:\n",
    "\n",
    "Fahrenheit = Celsius * 1.8 + 32\n",
    "\n",
    "Then, for any value of temperature in Celsius degree, I can obtain Fahrenheit degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db07a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def celsius_to_fahrenheit(v):\n",
    "    return v * 1.8 + 32\n",
    "\n",
    "celsius_to_fahrenheit(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fcc56",
   "metadata": {},
   "source": [
    "Now, in machine learning we do not know the formula or algorithm or transformation that transforms one value into the other. All we have is examples of inputs and corresponding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09498a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (-40, -40.0),\n",
    "    (-10, 14.0),\n",
    "    (0, 32.0),\n",
    "    (8, 46.4),\n",
    "    (15, 59.0),\n",
    "    (22, 71.6),\n",
    "    (38, 100.4)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e67c6",
   "metadata": {},
   "source": [
    "Then, we selected a model (in this example, a linear one), and fit it to the data. \n",
    "\n",
    "Note: For now, ignore all the implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ad182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "data = [\n",
    "    (-40, -40.0),\n",
    "    (-10, 14.0),\n",
    "    (0, 32.0),\n",
    "    (8, 46.4),\n",
    "    (15, 59.0),\n",
    "    (22, 71.6),\n",
    "    (38, 100.4)\n",
    "]\n",
    "\n",
    "# Convert data to tensors\n",
    "inputs = torch.tensor([data_point[0] for data_point in data], dtype=torch.float32).view(-1, 1)  # Celsius\n",
    "targets = torch.tensor([data_point[1] for data_point in data], dtype=torch.float32).view(-1, 1)  # Fahrenheit\n",
    "\n",
    "# Define the model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output feature (Fahrenheit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "lossi = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_input = torch.tensor([[30.0]])  # Celsius value to convert\n",
    "predicted_fahrenheit = model(test_input).item()\n",
    "print(f'Predicted Fahrenheit for 30Â°C: {predicted_fahrenheit:.1f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028aef5a",
   "metadata": {},
   "source": [
    "Lets take a look to how well is the network doing on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('# Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7cbaa",
   "metadata": {},
   "source": [
    "Now, lets make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5e8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = model(torch.tensor([100.0]).unsqueeze(1))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b548970",
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius_to_fahrenheit(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69a37f",
   "metadata": {},
   "source": [
    "Lets find the errors with some random celsius values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius_test = torch.randint(-30, 150, (12,))\n",
    "celsius_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158376c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fahrenheit_test = [celsius_to_fahrenheit(c) for c in celsius_test]\n",
    "print(fahrenheit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31a308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inferred_fahrenheit = model(celsius_test.to(torch.float).unsqueeze(1))\n",
    "print(inferred_fahrenheit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_square_error = sum((real-inferr)**2 for real, inferr in zip(fahrenheit_test, inferred_fahrenheit))\n",
    "mean_square_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc484a",
   "metadata": {},
   "source": [
    "Lets see what the network learned so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a282a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.weight, model.linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002b27f",
   "metadata": {},
   "source": [
    "Compare it with the actual equation:\n",
    "\n",
    "Fahrenheit = Celsius * 1.8 + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6455edd",
   "metadata": {},
   "source": [
    "In conclusion, we manage to build a **model** that correctly maps between Celsius degrees to Fahrenheit degrees based only in examples.\n",
    "\n",
    "**This machine learning task is knows as Regression and we use a Linear Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383e790",
   "metadata": {},
   "source": [
    "Lets see another example with a different task. We have some rules that allow us to classify the type of an animal based on some characteristics:\n",
    "\n",
    "- Weight > 100 kg:\n",
    "    - Yes: Hair?\n",
    "        - Yes: Bear\n",
    "        - No: Leave on water?\n",
    "            - Yes: Whale\n",
    "            - No: Anaconda\n",
    "    - No: Fly?\n",
    "        - Yes: Eagle\n",
    "        - No: Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad283c02",
   "metadata": {},
   "source": [
    "This is Biology, so if I have some animal description, I can automatically find which animal it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_animal(weight, hair, water, fly):\n",
    "    if weight > 100:\n",
    "        if hair:\n",
    "            return \"Bear\"\n",
    "        else:\n",
    "            if water:\n",
    "                return \"Whale\"\n",
    "            else:\n",
    "                return \"Anaconda\"\n",
    "    else:\n",
    "        if fly:\n",
    "            return \"Eagle\"\n",
    "        else:\n",
    "            return \"Cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_animal(120, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_animal(5, True, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f3752",
   "metadata": {},
   "source": [
    "The machile learning problem appears when I have some animal descriptions together with the current type of animal, and I want to create a model that, based on the descriptions, can infer the type of animal.\n",
    "\n",
    "First, generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce345eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_animals(n):    \n",
    "    result = []\n",
    "    for _ in range(n):\n",
    "        weight = random.randint(1, 200)\n",
    "        hair = random.random() > 0.5\n",
    "        water = random.random() > 0.5\n",
    "        fly = random.random() > 0.5\n",
    "        animal = get_animal(weight, hair, water, fly)\n",
    "        result.append((weight, hair, water, fly, animal))\n",
    "    return result    \n",
    "        \n",
    "for weight, hair, water, fly, animal in generate_random_animals(5):\n",
    "    print(weight, hair, water, fly, \"** Animal:\",  animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_random_animals(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['weight', 'hair', 'water', 'fly', 'animal'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['weight', 'hair', 'water', 'fly']\n",
    "X = df[feature_cols] # Features\n",
    "y = df.animal # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92668afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(r, p) for r, p in zip(y_test, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c5a97",
   "metadata": {},
   "source": [
    "Lets take a look to the model built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5531da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "text_representation = tree.export_text(clf, feature_names=['weight', 'hair', 'water', 'fly'])\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047de2de",
   "metadata": {},
   "source": [
    "**This machine learning task is known as suppervised classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f82c92",
   "metadata": {},
   "source": [
    "Lets see another example. Here we are trying to estimate the correct number from its handwritten image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define transformations to apply to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the tensor image with mean and standard deviation\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to show images with labels\n",
    "def imshow_with_labels(img, labels):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "    # Print labels near each image\n",
    "    num_images = len(labels)\n",
    "    grid_size = int(np.sqrt(num_images))\n",
    "    for i in range(num_images):\n",
    "        plt.text((i % grid_size) * 30, (i // grid_size) * 30, str(labels[i].item()), color='red', fontsize=12)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images and their labels\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Show images with labels\n",
    "imshow_with_labels(torchvision.utils.make_grid(images), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50614d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.targets[0], trainset.data[0], "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20896542",
   "metadata": {},
   "source": [
    "For solving this classification problem in a traditional way, we need to figure out and then calculate some \"features\" that differenciate from one class to the other. For example, one can be the total sum of elements on each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'feature': trainset.targets,\n",
    "    'value': torch.sum(trainset.data, axis=(1, 2)).numpy()\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data.boxplot(column='value', by='feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b0b2e",
   "metadata": {},
   "source": [
    "We can see that we can use this feature to differentiate between categories, but there is a lot of overlapping. Lets manufacture another feature, for example, the symmetries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical Symmetry\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'feature': trainset.targets,\n",
    "    'value': (torch.sum(trainset.data[:, :, :14], axis=(1, 2)) - \n",
    "              torch.sum(trainset.data[:, :, 14:], axis=(1, 2))\n",
    "              ).numpy()\n",
    "})\n",
    "\n",
    "# Create the box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "data.boxplot(column='value', by='feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0eb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'feature': trainset.targets,\n",
    "    'value': (torch.sum(trainset.data[:, :14, :], axis=(1, 2)) - \n",
    "              torch.sum(trainset.data[:, 14:, :], axis=(1, 2))\n",
    "              ).numpy()\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data.boxplot(column='value', by='feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f69ea0",
   "metadata": {},
   "source": [
    "We can now try to find some rules that allow us to classify each image, using the three manufactured features.\n",
    "\n",
    "The machine learning way is different. We create a model that can learn the relations, fit the model using available data, and then use the fitted model to classify digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the input tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf997db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "for l, p in zip(labels, predicted):\n",
    "    print(l, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b166d62",
   "metadata": {},
   "source": [
    "You can see that the problem was almost perfectly solved, with no need to manually engineering the features.\n",
    "\n",
    "**This task is also a suppervised classification, but using images as inputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368eea7",
   "metadata": {},
   "source": [
    "Lets see a final example. The manager of a chain of stores wants to understand the behavior of their customers in order to direct advertising campaigns to similar subsets of customers.\n",
    "\n",
    "The available data includes: gender, age, annual income, and a score between 0 and 100 that evaluates the magnitude of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a9ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Mall_Customers.csv\", index_col='CustomerID')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43caae8d",
   "metadata": {},
   "source": [
    "First, we simplify the name of some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf78290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={'Annual Income (k$)': 'Income',\n",
    "                              'Spending Score (1-100)': 'Score'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5abad3",
   "metadata": {},
   "source": [
    "Now, we will try to understand data using pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b180b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sn.pairplot(df, hue='Gender', aspect=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070651a",
   "metadata": {},
   "source": [
    "We conclude that gender is not important and can be removed from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Gender'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c123f9",
   "metadata": {},
   "source": [
    "We will use the KMeans clustering algorithm, which decomposes the dataframe into groups of objects that are very similar to each other and dissimilar to the objects in other groups. As a result, we also obtain a representative object for each group, which is the object most similar to the others.\n",
    "\n",
    "This algorithm takes the number of desired groups (k) as a parameter. Lets try with k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km3 = KMeans(n_clusters=3, n_init=\"auto\", random_state=314).fit(X)\n",
    "\n",
    "X['Labels'] = km3.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sn.scatterplot(x=X['Income'], y=X['Score'], hue=X['Labels'], \n",
    "                palette=sn.color_palette('hls', 3))\n",
    "plt.title('KMeans with 3 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697a7aa",
   "metadata": {},
   "source": [
    "Lets test what happen with k values from  2 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cdd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in range(2, 11):\n",
    "    km = KMeans(n_clusters=i, n_init=\"auto\", random_state=314).fit(X)\n",
    "    clusters.append(km.inertia_)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sn.lineplot(x=list(range(2, 11)), y=clusters, ax=ax)\n",
    "ax.set_title('Searching for Elbow')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "\n",
    "# Annotate arrow\n",
    "ax.annotate('Possible Elbow Point', xy=(3, 140000), xytext=(3, 50000), xycoords='data',          \n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n",
    "\n",
    "ax.annotate('Possible Elbow Point', xy=(5, 80000), xytext=(5, 150000), xycoords='data',          \n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e20f6",
   "metadata": {},
   "source": [
    "So, lets test with k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ace06",
   "metadata": {},
   "outputs": [],
   "source": [
    "km5 = KMeans(n_clusters=5, n_init=\"auto\", random_state=314).fit(X)\n",
    "\n",
    "X['Labels'] = km5.labels_\n",
    "plt.figure(figsize=(12, 8))\n",
    "sn.scatterplot(x=X['Income'], y=X['Score'], hue=X['Labels'], \n",
    "                palette=sn.color_palette('hls', 5))\n",
    "plt.title('KMeans with 3 Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da48346",
   "metadata": {},
   "source": [
    "The results with k=5 are better that with k=3. \n",
    "\n",
    "**Note** the highly subjective nature of this evaluation, as unlike previous examples, here we do not have prior knowledge to perform an objective evaluation.\n",
    "\n",
    "The 5 obtained clusters can be explained as follows:\n",
    "\n",
    "    Label 0: high income and low expenses\n",
    "    Label 1: low income and expenses\n",
    "    Label 2: high income and expenses\n",
    "    Label 3: average income and expenses\n",
    "    Label 4: low income and high expenses\n",
    "\n",
    "In conclusion, the client can notice that there is a segment with high income and low expenses, to which they could direct a more aggressive advertising strategy and potentially achieve good results.\n",
    "\n",
    "Another conclusion is that there is a segment that spends more than their income, which is interesting to consider.\n",
    "\n",
    "**This type of machine learning task is known as clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb1d25",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- In regular programming, we provide the algorithm or formula to transform the inputs in outputs\n",
    "- In machine learning, we provide examples of inputs and its corresponding outputs, and make the algorithms to figure out a good model for doing the transformation\n",
    "    - There are different models for performing each task\n",
    "    - Every model has different parameters that impacts the quality of the results\n",
    "    - Selecting the best option is a combination of experience and a trial-and-error strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abb4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
